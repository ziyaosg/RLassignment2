{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pLNcRVYvyiBx"
      },
      "outputs": [],
      "source": [
        "DISCRIMINATOR_LR = 0.00005\n",
        "DISCRIMINATOR_WD = 1e-5\n",
        "POLICY_LR = 0.0001\n",
        "LAMBDA_1 = 0.1\n",
        "LAMBDA_2 = 0.12\n",
        "EPOCH = 50\n",
        "BATCH_SIZE = 8\n",
        "TASK = 'coffee'\n",
        "VARIANCE = '1'    # D0 or D1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQhW2qw7e0NR"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9pRQbl2yrX7O"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable\n",
        "from torch.distributions import Categorical, Normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e-jyZ6W7YyFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06fe487c-35e3-4b8f-9fa8-df80f12c4587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/colab_ws\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# First, we need to decide where to host the runtime storage\n",
        "USE_GDRIVE_STORAGE = True\n",
        "\n",
        "if not USE_GDRIVE_STORAGE:\n",
        "    # Option 1: use the colab runtime storage. All trained model and downloaded\n",
        "    # will disappear after you disconnect from the runtime.\n",
        "    WS_DIR = \"/content/\"\n",
        "else:\n",
        "    # Option 2: use your google drive as the runtime storage. You need to grant\n",
        "    # permission for the colab runtime to access your google drive. You also\n",
        "    # need to decide on a workspace for robomimic. In this case, we've created a\n",
        "    # folder called \"colab_ws\" in Google Drive.\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    WS_DIR = \"/content/drive/MyDrive/colab_ws/\" # this should be the absolute path, e.g., \"/content/drive/MyDrive/my-ws/\"\n",
        "    assert os.path.exists(WS_DIR)\n",
        "\n",
        "%cd $WS_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3s0LNum1Y2eP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d161b8-823e-403c-f12e-3d076d7cec33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/colab_ws\n",
            "Obtaining file:///content/drive/MyDrive/colab_ws/robosuite\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from robosuite==1.4.1) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.49.1 in /usr/local/lib/python3.10/dist-packages (from robosuite==1.4.1) (0.58.1)\n",
            "Requirement already satisfied: scipy>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from robosuite==1.4.1) (1.11.4)\n",
            "Requirement already satisfied: mujoco>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from robosuite==1.4.1) (2.3.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from robosuite==1.4.1) (9.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from robosuite==1.4.1) (4.8.0.76)\n",
            "Requirement already satisfied: pynput in /usr/local/lib/python3.10/dist-packages (from robosuite==1.4.1) (1.7.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from robosuite==1.4.1) (2.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.0->robosuite==1.4.1) (1.4.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.0->robosuite==1.4.1) (2.7.0)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.0->robosuite==1.4.1) (3.1.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49.1->robosuite==1.4.1) (0.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pynput->robosuite==1.4.1) (1.16.0)\n",
            "Requirement already satisfied: evdev>=1.3 in /usr/local/lib/python3.10/dist-packages (from pynput->robosuite==1.4.1) (1.7.0)\n",
            "Requirement already satisfied: python-xlib>=0.17 in /usr/local/lib/python3.10/dist-packages (from pynput->robosuite==1.4.1) (0.33)\n",
            "Building wheels for collected packages: robosuite\n",
            "  Building editable for robosuite (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for robosuite: filename=robosuite-1.4.1-0.editable-py3-none-any.whl size=6804 sha256=ef26163a4ecd25e29cb6e66b3e9ba0b0dfb7c971aff87f133e81ea00e06eda33\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rd74c4qn/wheels/07/97/34/c35a2d0b7f1dab8a60b73d241ad0302d7d627ab89e6a23c480\n",
            "Successfully built robosuite\n",
            "Installing collected packages: robosuite\n",
            "  Attempting uninstall: robosuite\n",
            "    Found existing installation: robosuite 1.4.1\n",
            "    Uninstalling robosuite-1.4.1:\n",
            "      Successfully uninstalled robosuite-1.4.1\n",
            "Successfully installed robosuite-1.4.1\n",
            "Obtaining file:///content/drive/MyDrive/colab_ws/robomimic\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (3.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (4.66.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (2.4.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (2.15.2)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (2.6.2.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (0.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (3.7.1)\n",
            "Requirement already satisfied: egl_probe>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (1.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from robomimic==0.3.0) (0.17.1+cu121)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio->robomimic==0.3.0) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg->robomimic==0.3.0) (67.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->robomimic==0.3.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->robomimic==0.3.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->robomimic==0.3.0) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->robomimic==0.3.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->robomimic==0.3.0) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->robomimic==0.3.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->robomimic==0.3.0) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->robomimic==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->robomimic==0.3.0) (1.62.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->robomimic==0.3.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->robomimic==0.3.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->robomimic==0.3.0) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->robomimic==0.3.0) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->robomimic==0.3.0) (2.31.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->robomimic==0.3.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->robomimic==0.3.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->robomimic==0.3.0) (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->robomimic==0.3.0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->robomimic==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->robomimic==0.3.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->robomimic==0.3.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->robomimic==0.3.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->robomimic==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->robomimic==0.3.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->robomimic==0.3.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->robomimic==0.3.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->robomimic==0.3.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->robomimic==0.3.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->robomimic==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->robomimic==0.3.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->robomimic==0.3.0) (3.2.2)\n",
            "Installing collected packages: robomimic\n",
            "  Attempting uninstall: robomimic\n",
            "    Found existing installation: robomimic 0.3.0\n",
            "    Uninstalling robomimic-0.3.0:\n",
            "      Successfully uninstalled robomimic-0.3.0\n",
            "  Running setup.py develop for robomimic\n",
            "Successfully installed robomimic-0.3.0\n",
            "Obtaining file:///content/drive/MyDrive/colab_ws/mimicgen_environments\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from mimicgen-envs==0.1.0) (1.25.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from mimicgen-envs==0.1.0) (3.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mimicgen-envs==0.1.0) (4.66.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from mimicgen-envs==0.1.0) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from mimicgen-envs==0.1.0) (0.4.9)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from mimicgen-envs==0.1.0) (5.1.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from mimicgen-envs==0.1.0) (5.2.0)\n",
            "Requirement already satisfied: mujoco==2.3.2 in /usr/local/lib/python3.10/dist-packages (from mimicgen-envs==0.1.0) (2.3.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco==2.3.2->mimicgen-envs==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco==2.3.2->mimicgen-envs==0.1.0) (2.7.0)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco==2.3.2->mimicgen-envs==0.1.0) (3.1.7)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->mimicgen-envs==0.1.0) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->mimicgen-envs==0.1.0) (3.13.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->mimicgen-envs==0.1.0) (2.31.0)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio->mimicgen-envs==0.1.0) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg->mimicgen-envs==0.1.0) (67.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->mimicgen-envs==0.1.0) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->mimicgen-envs==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->mimicgen-envs==0.1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->mimicgen-envs==0.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->mimicgen-envs==0.1.0) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->mimicgen-envs==0.1.0) (1.7.1)\n",
            "Installing collected packages: mimicgen-envs\n",
            "  Attempting uninstall: mimicgen-envs\n",
            "    Found existing installation: mimicgen-envs 0.1.0\n",
            "    Uninstalling mimicgen-envs-0.1.0:\n",
            "      Successfully uninstalled mimicgen-envs-0.1.0\n",
            "  Running setup.py develop for mimicgen-envs\n",
            "Successfully installed mimicgen-envs-0.1.0\n",
            "Requirement already satisfied: mujoco in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco) (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.25.2)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco) (3.1.7)\n"
          ]
        }
      ],
      "source": [
        "# Install the basic requirements\n",
        "%cd $WS_DIR\n",
        "!pip install -e robosuite/\n",
        "!pip install -e robomimic/\n",
        "!pip install -e mimicgen_environments/\n",
        "!pip install mujoco\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('./robosuite/')\n",
        "sys.path.append('./robomimic/')\n",
        "sys.path.append('./mimicgen_environments/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y56ecs8rY7k5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# enforce that the dataset exists\n",
        "DATA_DIR = WS_DIR + \"mimicgen_data/\"\n",
        "dataset_path = os.path.join(DATA_DIR, TASK + \"_d\" + VARIANCE + \"_100.hdf5\")\n",
        "assert os.path.exists(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XrlNvPjerSp"
      },
      "source": [
        "## Architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hwpYkovPrcol"
      },
      "outputs": [],
      "source": [
        "class Policy(nn.Module):\n",
        "    def __init__(self, img_dim, combined_dim, action_dim):\n",
        "        super(Policy, self).__init__()\n",
        "        self.im = nn.Sequential(\n",
        "            nn.Conv2d(img_dim[2], 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        self.feature_dim = 128 * (img_dim[0] // 8 + 1) * (img_dim[1] // 8 + 1)\n",
        "\n",
        "        self.fully_connected = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim + combined_dim, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 64)\n",
        "        )\n",
        "\n",
        "        self.action_mean = nn.Linear(64, action_dim)\n",
        "        self.action_mean.weight.data.mul_(0.1)\n",
        "        self.action_mean.bias.data.mul_(0.1)\n",
        "\n",
        "        self.action_log_std = nn.Parameter(abs(torch.randn(1, action_dim)))\n",
        "\n",
        "    def forward(self, img, combined_features):\n",
        "        x = self.im(img)\n",
        "        x = torch.cat([x, combined_features], dim=-1)\n",
        "        x = self.fully_connected(x)\n",
        "\n",
        "        action_mean = self.action_mean(x)\n",
        "\n",
        "        return action_mean\n",
        "\n",
        "    def log_std_and_std(self, action_means):\n",
        "        action_log_std = self.action_log_std.expand_as(action_means)\n",
        "        return action_log_std, torch.exp(action_log_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rr6kMPcJrgKU"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_dim, combined_dim, action_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.im = nn.Sequential(\n",
        "            nn.Conv2d(img_dim[2], 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        self.feature_dim = 128 * (img_dim[0] // 8 + 1) * (img_dim[1] // 8 + 1)\n",
        "\n",
        "        self.fully_connected = nn.Sequential(\n",
        "            nn.Linear(self.feature_dim + combined_dim + action_dim, 256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, combined_features, action):\n",
        "        x = self.im(img)\n",
        "        x = torch.cat([x, combined_features, action], dim=-1)\n",
        "        return self.fully_connected(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "m93GiDEFac2S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MimicGenDataset(Dataset):\n",
        "    def __init__(self, file_path):\n",
        "        self.file = h5py.File(file_path, 'r')\n",
        "        self.demos = list(self.file['data'].keys())\n",
        "        inds = np.argsort([int(elem.split('_')[1]) for elem in self.demos])\n",
        "        self.demos = [self.demos[i] for i in inds]\n",
        "        random.shuffle(self.demos)\n",
        "        self.combined_dim = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.demos)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        demo_key = self.demos[idx]\n",
        "        demo_grp = self.file['data'][demo_key]\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        e_imgs = torch.tensor(demo_grp['obs']['agentview_image'][:], dtype=torch.float32).permute(0, 3, 1, 2).to(device)\n",
        "        e_obj = torch.tensor(demo_grp['obs']['object'][:], dtype=torch.float32).to(device)\n",
        "        e_eef_pos = torch.tensor(demo_grp['obs']['robot0_eef_pos'][:], dtype=torch.float32).to(device)\n",
        "        e_eef_quat = torch.tensor(demo_grp['obs']['robot0_eef_quat'][:], dtype=torch.float32).to(device)\n",
        "        e_joint_pos = torch.tensor(demo_grp['obs']['robot0_joint_pos'][:], dtype=torch.float32).to(device)\n",
        "        e_actions = torch.tensor(demo_grp['actions'][:], dtype=torch.float32).to(device)\n",
        "        e_states = torch.tensor(demo_grp['states'][:], dtype=torch.float32).to(device)\n",
        "\n",
        "        combined_features = torch.cat([e_obj, e_eef_pos, e_eef_quat, e_joint_pos, e_states], dim=1)\n",
        "\n",
        "        return e_imgs, combined_features, e_actions\n",
        "\n",
        "    def close(self):\n",
        "        self.file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcVxszWceYzq"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F7v2XMoUfD1X"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# enforce that the dataset exists\n",
        "DATA_DIR = WS_DIR + \"mimicgen_data/\"\n",
        "dataset_path = os.path.join(DATA_DIR, TASK + \"_d\" + VARIANCE + \"_100.hdf5\")\n",
        "assert os.path.exists(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Hdxm1sDabQHN"
      },
      "outputs": [],
      "source": [
        "dataset = MimicGenDataset(dataset_path)\n",
        "data_loader = DataLoader(\n",
        "    dataset=dataset,\n",
        "    sampler=None,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vr41VuEcrpQX"
      },
      "outputs": [],
      "source": [
        "# def train_info_gail(policy, discriminator, lambda1, lambda2, expert, demo):\n",
        "def train_info_gail(policy, discriminator, lambda1, lambda2):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    discriminator.to(device)\n",
        "    policy.to(device)\n",
        "\n",
        "    discriminator_optimizer = optim.SGD(discriminator.parameters(), lr=DISCRIMINATOR_LR, weight_decay=DISCRIMINATOR_WD)\n",
        "    policy_optimizer = optim.Adam(policy.parameters(), lr=POLICY_LR)\n",
        "\n",
        "    adv_loss = nn.BCELoss()\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(EPOCH):\n",
        "        # random.shuffle(demos)\n",
        "\n",
        "        i = 0\n",
        "\n",
        "        progress_bar = tqdm(enumerate(dataset), total=len(dataset), desc=f\"Epoch {epoch}\")\n",
        "        # progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch}\")\n",
        "        # for i, demo_key in progress_bar:\n",
        "        for i, data in progress_bar:\n",
        "\n",
        "            e_imgs, combined_features, e_actions = data\n",
        "\n",
        "            real_labels = torch.ones(e_actions.shape[0], 1).to(device)\n",
        "            fake_labels = torch.zeros(e_actions.shape[0], 1).to(device)\n",
        "\n",
        "            # Update Discriminator\n",
        "            discriminator_optimizer.zero_grad()\n",
        "            real_predictions = discriminator(e_imgs, combined_features, e_actions)\n",
        "            fake_actions = policy(e_imgs, combined_features).detach()\n",
        "            fake_predictions = discriminator(e_imgs, combined_features, fake_actions)\n",
        "            discriminator_loss = adv_loss(real_predictions, real_labels) + adv_loss(fake_predictions, fake_labels)\n",
        "            discriminator_loss.backward()\n",
        "            discriminator_optimizer.step()\n",
        "\n",
        "            # Update Generator\n",
        "            policy_optimizer.zero_grad()\n",
        "            fake_actions = policy(e_imgs, combined_features)\n",
        "            fake_predictions = discriminator(e_imgs, combined_features, fake_actions)\n",
        "            generator_loss = lambda1 * adv_loss(fake_predictions, real_labels)\n",
        "            bc_loss = lambda2 * mse_loss(fake_actions, e_actions)\n",
        "            total_policy_loss = generator_loss + bc_loss\n",
        "            total_policy_loss.backward()\n",
        "            policy_optimizer.step()\n",
        "\n",
        "            progress_bar.set_description(f\"\"\"Epoch {epoch+1} | Iter {i} | Discriminator Loss: {discriminator_loss.item():.4f} | Policy Loss: {total_policy_loss.item():.4f}\"\"\")\n",
        "            # i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wn83_cKoFDFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0d46c2-321d-4ec6-8232-cbcef6b36ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============= Initialized Observation Utils with Obs Spec =============\n",
            "\n",
            "using obs modality: low_dim with keys: ['robot0_eef_pos']\n",
            "using obs modality: rgb with keys: []\n"
          ]
        }
      ],
      "source": [
        "import robomimic.utils.obs_utils as ObsUtils\n",
        "\n",
        "# We normally need to make sure robomimic knows which observations are images (for the\n",
        "# data processing pipeline). This is usually inferred from your training config, but\n",
        "# since we are just playing back demonstrations, we just need to initialize robomimic\n",
        "# with a dummy spec.\n",
        "dummy_spec = dict(\n",
        "    obs=dict(\n",
        "            low_dim=[\"robot0_eef_pos\"],\n",
        "            rgb=[],\n",
        "        ),\n",
        ")\n",
        "ObsUtils.initialize_obs_utils_with_obs_specs(obs_modality_specs=dummy_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvaBrFoAFFqu",
        "outputId": "ee0a84a1-241f-471b-b432-d21e0007fb55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/colab_ws/./robosuite/robosuite/macros.py:53: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
            "  ROBOSUITE_DEFAULT_LOGGER.warn(\"No private macro file found!\")\n",
            "[robosuite WARNING] No private macro file found! (macros.py:53)\n",
            "WARNING:robosuite_logs:No private macro file found!\n",
            "[robosuite WARNING] It is recommended to use a private macro file (macros.py:54)\n",
            "WARNING:robosuite_logs:It is recommended to use a private macro file\n",
            "[robosuite WARNING] To setup, run: python /content/drive/MyDrive/colab_ws/./robosuite/robosuite/scripts/setup_macros.py (macros.py:55)\n",
            "WARNING:robosuite_logs:To setup, run: python /content/drive/MyDrive/colab_ws/./robosuite/robosuite/scripts/setup_macros.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: robosuite task zoo environments not imported since robosuite task zoo is not installed!\n",
            "Created environment with name Coffee_D1\n",
            "Action size is 7\n"
          ]
        }
      ],
      "source": [
        "import robomimic.utils.env_utils as EnvUtils\n",
        "\n",
        "f = h5py.File(dataset_path, \"r\")\n",
        "env_meta = json.loads(f[\"data\"].attrs[\"env_args\"])\n",
        "\n",
        "# create simulation environment from environment metedata\n",
        "env = EnvUtils.create_env_from_metadata(\n",
        "    env_meta=env_meta,\n",
        "    render=False,            # no on-screen rendering\n",
        "    render_offscreen=True,   # off-screen rendering to support rendering video frames\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aclRaOYraIoC",
        "outputId": "6a15167b-2ddd-4c03-b922-16a2a337956b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "_, combined_features, _ = dataset[0]\n",
        "combined_dim = combined_features.shape[1]\n",
        "print(combined_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5bC-3yr4f54"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjcO_iyJAtOw",
        "outputId": "b8373fd2-308e-408c-893c-54917cf2ad5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 | Iter 99 | Discriminator Loss: 1.4036 | Policy Loss: 0.0980: 100%|██████████| 100/100 [00:09<00:00, 10.15it/s]\n",
            "Epoch 2 | Iter 99 | Discriminator Loss: 1.3993 | Policy Loss: 0.0958: 100%|██████████| 100/100 [00:08<00:00, 11.44it/s]\n",
            "Epoch 3 | Iter 99 | Discriminator Loss: 1.3962 | Policy Loss: 0.0900: 100%|██████████| 100/100 [00:08<00:00, 11.74it/s]\n",
            "Epoch 4 | Iter 99 | Discriminator Loss: 1.3949 | Policy Loss: 0.0893: 100%|██████████| 100/100 [00:08<00:00, 11.76it/s]\n",
            "Epoch 5 | Iter 99 | Discriminator Loss: 1.3939 | Policy Loss: 0.0875: 100%|██████████| 100/100 [00:08<00:00, 11.59it/s]\n",
            "Epoch 6 | Iter 99 | Discriminator Loss: 1.3929 | Policy Loss: 0.0847: 100%|██████████| 100/100 [00:08<00:00, 11.67it/s]\n",
            "Epoch 7 | Iter 99 | Discriminator Loss: 1.3923 | Policy Loss: 0.0825: 100%|██████████| 100/100 [00:08<00:00, 11.72it/s]\n",
            "Epoch 8 | Iter 99 | Discriminator Loss: 1.3916 | Policy Loss: 0.0831: 100%|██████████| 100/100 [00:08<00:00, 11.75it/s]\n",
            "Epoch 9 | Iter 99 | Discriminator Loss: 1.3910 | Policy Loss: 0.0828: 100%|██████████| 100/100 [00:08<00:00, 11.63it/s]\n",
            "Epoch 10 | Iter 99 | Discriminator Loss: 1.3905 | Policy Loss: 0.0834: 100%|██████████| 100/100 [00:08<00:00, 11.67it/s]\n",
            "Epoch 11 | Iter 99 | Discriminator Loss: 1.3900 | Policy Loss: 0.0801: 100%|██████████| 100/100 [00:08<00:00, 11.77it/s]\n",
            "Epoch 12 | Iter 99 | Discriminator Loss: 1.3896 | Policy Loss: 0.0801: 100%|██████████| 100/100 [00:08<00:00, 11.46it/s]\n",
            "Epoch 13 | Iter 99 | Discriminator Loss: 1.3893 | Policy Loss: 0.0790: 100%|██████████| 100/100 [00:08<00:00, 11.74it/s]\n",
            "Epoch 14 | Iter 99 | Discriminator Loss: 1.3890 | Policy Loss: 0.0818: 100%|██████████| 100/100 [00:08<00:00, 11.73it/s]\n",
            "Epoch 15 | Iter 99 | Discriminator Loss: 1.3888 | Policy Loss: 0.0787: 100%|██████████| 100/100 [00:08<00:00, 11.78it/s]\n",
            "Epoch 16 | Iter 99 | Discriminator Loss: 1.3886 | Policy Loss: 0.0805: 100%|██████████| 100/100 [00:08<00:00, 11.53it/s]\n",
            "Epoch 17 | Iter 99 | Discriminator Loss: 1.3885 | Policy Loss: 0.0796: 100%|██████████| 100/100 [00:08<00:00, 11.55it/s]\n",
            "Epoch 18 | Iter 99 | Discriminator Loss: 1.3884 | Policy Loss: 0.0790: 100%|██████████| 100/100 [00:08<00:00, 11.51it/s]\n",
            "Epoch 19 | Iter 99 | Discriminator Loss: 1.3882 | Policy Loss: 0.0784: 100%|██████████| 100/100 [00:08<00:00, 11.75it/s]\n",
            "Epoch 20 | Iter 99 | Discriminator Loss: 1.3881 | Policy Loss: 0.0777: 100%|██████████| 100/100 [00:08<00:00, 11.74it/s]\n",
            "Epoch 21 | Iter 99 | Discriminator Loss: 1.3880 | Policy Loss: 0.0765: 100%|██████████| 100/100 [00:08<00:00, 11.70it/s]\n",
            "Epoch 22 | Iter 99 | Discriminator Loss: 1.3878 | Policy Loss: 0.0776: 100%|██████████| 100/100 [00:08<00:00, 11.71it/s]\n",
            "Epoch 23 | Iter 99 | Discriminator Loss: 1.3878 | Policy Loss: 0.0780: 100%|██████████| 100/100 [00:08<00:00, 11.68it/s]\n",
            "Epoch 24 | Iter 99 | Discriminator Loss: 1.3878 | Policy Loss: 0.0764: 100%|██████████| 100/100 [00:08<00:00, 11.63it/s]\n",
            "Epoch 25 | Iter 99 | Discriminator Loss: 1.3877 | Policy Loss: 0.0759: 100%|██████████| 100/100 [00:08<00:00, 11.78it/s]\n",
            "Epoch 26 | Iter 99 | Discriminator Loss: 1.3877 | Policy Loss: 0.0776: 100%|██████████| 100/100 [00:08<00:00, 11.64it/s]\n",
            "Epoch 27 | Iter 99 | Discriminator Loss: 1.3876 | Policy Loss: 0.0755: 100%|██████████| 100/100 [00:08<00:00, 11.75it/s]\n",
            "Epoch 28 | Iter 99 | Discriminator Loss: 1.3876 | Policy Loss: 0.0763: 100%|██████████| 100/100 [00:08<00:00, 11.79it/s]\n",
            "Epoch 29 | Iter 99 | Discriminator Loss: 1.3875 | Policy Loss: 0.0780: 100%|██████████| 100/100 [00:08<00:00, 11.73it/s]\n",
            "Epoch 30 | Iter 99 | Discriminator Loss: 1.3875 | Policy Loss: 0.0745: 100%|██████████| 100/100 [00:08<00:00, 11.69it/s]\n",
            "Epoch 31 | Iter 99 | Discriminator Loss: 1.3874 | Policy Loss: 0.0759: 100%|██████████| 100/100 [00:08<00:00, 11.70it/s]\n",
            "Epoch 32 | Iter 99 | Discriminator Loss: 1.3875 | Policy Loss: 0.0751: 100%|██████████| 100/100 [00:08<00:00, 11.76it/s]\n",
            "Epoch 33 | Iter 99 | Discriminator Loss: 1.3875 | Policy Loss: 0.0759: 100%|██████████| 100/100 [00:08<00:00, 11.59it/s]\n",
            "Epoch 34 | Iter 99 | Discriminator Loss: 1.3874 | Policy Loss: 0.0749: 100%|██████████| 100/100 [00:08<00:00, 11.65it/s]\n",
            "Epoch 35 | Iter 99 | Discriminator Loss: 1.3874 | Policy Loss: 0.0768: 100%|██████████| 100/100 [00:08<00:00, 11.66it/s]\n",
            "Epoch 36 | Iter 99 | Discriminator Loss: 1.3874 | Policy Loss: 0.0754: 100%|██████████| 100/100 [00:08<00:00, 11.61it/s]\n",
            "Epoch 37 | Iter 99 | Discriminator Loss: 1.3874 | Policy Loss: 0.0742: 100%|██████████| 100/100 [00:08<00:00, 11.60it/s]\n",
            "Epoch 38 | Iter 99 | Discriminator Loss: 1.3874 | Policy Loss: 0.0731: 100%|██████████| 100/100 [00:08<00:00, 11.64it/s]\n",
            "Epoch 39 | Iter 99 | Discriminator Loss: 1.3873 | Policy Loss: 0.0732: 100%|██████████| 100/100 [00:08<00:00, 11.59it/s]\n",
            "Epoch 40 | Iter 99 | Discriminator Loss: 1.3873 | Policy Loss: 0.0731: 100%|██████████| 100/100 [00:08<00:00, 11.68it/s]\n",
            "Epoch 41 | Iter 99 | Discriminator Loss: 1.3873 | Policy Loss: 0.0735: 100%|██████████| 100/100 [00:08<00:00, 11.65it/s]\n",
            "Epoch 42 | Iter 99 | Discriminator Loss: 1.3873 | Policy Loss: 0.0735: 100%|██████████| 100/100 [00:08<00:00, 11.69it/s]\n",
            "Epoch 43 | Iter 99 | Discriminator Loss: 1.3873 | Policy Loss: 0.0753: 100%|██████████| 100/100 [00:08<00:00, 11.78it/s]\n",
            "Epoch 44 | Iter 99 | Discriminator Loss: 1.3872 | Policy Loss: 0.0730: 100%|██████████| 100/100 [00:08<00:00, 11.67it/s]\n",
            "Epoch 45 | Iter 99 | Discriminator Loss: 1.3872 | Policy Loss: 0.0728: 100%|██████████| 100/100 [00:08<00:00, 11.66it/s]\n",
            "Epoch 46 | Iter 99 | Discriminator Loss: 1.3872 | Policy Loss: 0.0733: 100%|██████████| 100/100 [00:08<00:00, 11.80it/s]\n",
            "Epoch 47 | Iter 99 | Discriminator Loss: 1.3873 | Policy Loss: 0.0732: 100%|██████████| 100/100 [00:08<00:00, 11.68it/s]\n",
            "Epoch 48 | Iter 99 | Discriminator Loss: 1.3872 | Policy Loss: 0.0725: 100%|██████████| 100/100 [00:08<00:00, 11.67it/s]\n",
            "Epoch 49 | Iter 99 | Discriminator Loss: 1.3872 | Policy Loss: 0.0727: 100%|██████████| 100/100 [00:08<00:00, 11.69it/s]\n",
            "Epoch 50 | Iter 99 | Discriminator Loss: 1.3872 | Policy Loss: 0.0728: 100%|██████████| 100/100 [00:08<00:00, 11.74it/s]\n"
          ]
        }
      ],
      "source": [
        "policy = Policy((84, 84, 3), combined_dim, 7)\n",
        "discriminator = Discriminator((84, 84, 3), combined_dim, 7)\n",
        "lambda1 = LAMBDA_1\n",
        "lambda2 = LAMBDA_2\n",
        "\n",
        "train_info_gail(policy, discriminator, lambda1, lambda2)\n",
        "\n",
        "string = WS_DIR + TASK + '_policy.pt'\n",
        "torch.save(policy, string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wl1nuJEihGK"
      },
      "source": [
        "## Rollouut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIrbY6T8t9ji",
        "outputId": "087249ac-54de-4139-8aec-957505040ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "\n",
        "# prepare to write playback trajectories to video\n",
        "video_path = os.path.join(DATA_DIR, TASK + \"_playback.mp4\")\n",
        "video_writer = imageio.get_writer(video_path, fps=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "t_Di8_qAt82W"
      },
      "outputs": [],
      "source": [
        "def playback_trajectory(demo_key):\n",
        "    \"\"\"\n",
        "    Simple helper function to playback the trajectory stored under the hdf5 group @demo_key and\n",
        "    write frames rendered from the simulation to the active @video_writer.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # robosuite datasets store the ground-truth simulator states under the \"states\" key.\n",
        "    # We will use the first one, alone with the model xml, to reset the environment to\n",
        "    # the initial configuration before playing back actions.\n",
        "    init_state = f[\"data/{}/states\".format(demo_key)][0]\n",
        "    model_xml = f[\"data/{}\".format(demo_key)].attrs[\"model_file\"]\n",
        "    initial_state_dict = dict(states=init_state, model=model_xml)\n",
        "\n",
        "    # reset to initial state\n",
        "    env.reset_to(initial_state_dict)\n",
        "\n",
        "    # playback actions one by one, and render frames\n",
        "\n",
        "    e_actions = f[\"data/{}/actions\".format(demo_key)][:]\n",
        "\n",
        "    # Generate trajectories\n",
        "    state = env.get_state()['states']\n",
        "    ob = env.get_observation()\n",
        "\n",
        "    img = env.render(mode=\"rgb_array\", height=84, width=84, camera_name=\"agentview\")\n",
        "    obj = ob['object']\n",
        "\n",
        "    eef_pos = ob['robot0_eef_pos']\n",
        "    eef_quat = ob['robot0_eef_quat']\n",
        "    joint_pos = ob['robot0_joint_pos']\n",
        "\n",
        "\n",
        "    for t in tqdm(range(1000)):\n",
        "        img_tensor = torch.tensor(img.copy(), dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2).to(device)\n",
        "\n",
        "        obj_tensor = torch.tensor(obj, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        eef_pos_tensor = torch.tensor(eef_pos, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        eef_quat_tensor = torch.tensor(eef_quat, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "        joint_pos_tensor = torch.tensor(joint_pos, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "        combined_features = torch.cat([obj_tensor, eef_pos_tensor, eef_quat_tensor, joint_pos_tensor, state_tensor], dim=1)\n",
        "\n",
        "\n",
        "        action_mean = policy(img_tensor, combined_features)\n",
        "        action_log_std, action_std = policy.log_std_and_std(action_mean)\n",
        "        action = action_mean\n",
        "        env.step(action.detach().cpu().numpy()[0])\n",
        "        state = env.get_state()['states']\n",
        "        ob = env.get_observation()\n",
        "        img = env.render(mode=\"rgb_array\", height=84, width=84, camera_name=\"agentview\")\n",
        "        obj = ob['object']\n",
        "        video_img = env.render(mode=\"rgb_array\", height=512, width=512, camera_name=\"agentview\")\n",
        "        video_writer.append_data(video_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wyAbMRuupRA",
        "outputId": "0196b1c1-8360-43e2-bc88-8f735ef03520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Playing back demo key: demo_540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1000 [00:00<?, ?it/s]/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "100%|██████████| 1000/1000 [03:59<00:00,  4.17it/s]\n"
          ]
        }
      ],
      "source": [
        "# playback the first 3 demos and record them to a video file\n",
        "for ep in dataset.demos[:1]:\n",
        "    print(\"Playing back demo key: {}\".format(ep))\n",
        "    playback_trajectory(ep)\n",
        "\n",
        "# done writing video\n",
        "video_writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvQVpnDCvP4D"
      },
      "outputs": [],
      "source": [
        "# view the trajectories!\n",
        "from IPython.display import Video\n",
        "Video(video_path, embed=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICIz56H6BIdJ"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwRc8AsTBKQd"
      },
      "outputs": [],
      "source": [
        "eval_path = os.path.join(DATA_DIR, TASK + \"_d\" + VARIANCE + \"_test.hdf5\")\n",
        "testset = MimicGenDataset(eval_path)\n",
        "test_loader = DataLoader(\n",
        "    dataset=testset,\n",
        "    sampler=None,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nw45OaJGmcSL"
      },
      "outputs": [],
      "source": [
        "_, combined_features, _ = testset[0]\n",
        "combined_dim = combined_features.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "914PLPMgmUbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0da04ed-2d26-467c-b373-dfda9c7100bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average MSE Loss: 0.1167: 100%|██████████| 100/100 [00:05<00:00, 16.87it/s]\n"
          ]
        }
      ],
      "source": [
        "model = Policy((84, 84, 3), combined_dim, 7)\n",
        "save_position = WS_DIR + TASK + '_policy.pt'\n",
        "model = torch.load(save_position)\n",
        "model.eval()\n",
        "test_g_loss = 0.0\n",
        "num_batches = 0\n",
        "\n",
        "# progress_bar = tqdm(test_loader, desc=f'Eval')\n",
        "progress_bar = tqdm(enumerate(testset), total=len(testset), desc=f\"Evaluation\")\n",
        "\n",
        "for i, data in progress_bar:\n",
        "# for data in progress_bar:\n",
        "    e_imgs, combined_features, e_actions = data\n",
        "\n",
        "    g_outputs = model(e_imgs, combined_features)\n",
        "    g_loss = nn.MSELoss()(g_outputs, e_actions)\n",
        "    test_g_loss += g_loss.item()\n",
        "\n",
        "    num_batches += 1\n",
        "\n",
        "    progress_bar.set_description(f\"Average MSE Loss: {test_g_loss/num_batches:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tVMHPMMHvKYr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}